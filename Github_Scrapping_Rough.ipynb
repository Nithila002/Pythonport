{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c161fa",
   "metadata": {},
   "source": [
    "## SCRAPPING_GITHUB_TOPIC_RESPIRATORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b4857",
   "metadata": {},
   "source": [
    "#### Use the request library to download web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url = \"https://github.com/topics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webpage.html', 'w') as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702eb68",
   "metadata": {},
   "source": [
    "#### Use Beautiful Soup to parse and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb72c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f08f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title_tags = doc.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "topic_title_tags = doc.find_all('p', {'class': selection_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topic_title_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_desc_tags = doc.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "topic_desc_tags = doc.find_all('p', {'class': selection_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_desc_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd59a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title_tag0 = topic_title_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9eb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag = topic_title_tag0.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-grow-0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46429fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic0_url = 'https://github.com' + topic_link_tags[0] ['href']\n",
    "print(topic0_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_titles = []\n",
    "\n",
    "for tag in topic_title_tags:\n",
    "    topic_titles.append(tag.text)\n",
    "print(topic_titles)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_descriptions = []\n",
    "\n",
    "for tag in topic_desc_tags:\n",
    "    topic_descriptions.append(tag.text.strip())\n",
    "    \n",
    "print(topic_descriptions[:5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_urls = []\n",
    "base_url = 'https://github.com'\n",
    "\n",
    "for tag in topic_link_tags:\n",
    "    topic_urls.append(base_url + tag['href'])\n",
    "\n",
    "topic_urls    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a40d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = {\n",
    "    'Title' : topic_titles,\n",
    "    'Description' : topic_descriptions,\n",
    "    'URL' : topic_urls\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49edc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d5e62",
   "metadata": {},
   "source": [
    "#### Create CSV file(s) with the extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv('topics.csv', index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ac69b",
   "metadata": {},
   "source": [
    "#### Getting information out of a topic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_page_url = topic_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a91ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topic_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f187e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990158a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "repo_tags = topic_doc.find_all('h3',{'class':h3_selection_class })\n",
    "\n",
    "repo_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d257a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags = repo_tags[0].find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9584ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags[1].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a43b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_urls = 'https://github.com'\n",
    "repo_url = base_url + a_tags[1]['href']\n",
    "print(repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff098d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags = topic_doc.find_all('span',{'class': 'Counter js-social-count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(star_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1236cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_star_count(star_tags[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7214ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h3_tag, star_tag):\n",
    "    #returns all the required information about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars =  parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_repo_info(repo_tags[0], star_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e992f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_repos_dict = {\n",
    "    'UserName': [],\n",
    "    'Repo_Name': [],\n",
    "    'Stars': [],\n",
    "    'Repo_URL': []\n",
    "}\n",
    "\n",
    "for i in range(len(repo_tags)) :\n",
    "    repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "    topics_repos_dict['UserName'].append(repo_info[0])\n",
    "    topics_repos_dict['Repo_Name'].append(repo_info[1])\n",
    "    topics_repos_dict['Stars'].append(repo_info[2])\n",
    "    topics_repos_dict['Repo_URL'].append(repo_info[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_topic_page(topic_url):\n",
    "    \n",
    "    # download the page\n",
    "    response = requests.get(topic_url)\n",
    "    \n",
    "   # check successfull response\n",
    "    if response.status_code != 200:\n",
    "          raise Exception ('Failed to load page{}'.format(topic_url))\n",
    "            \n",
    "   # parse using beautifulsoup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')   \n",
    "    return topic_doc\n",
    "\n",
    "def get_repo_info(h3_tag, star_tag):\n",
    "    \n",
    "    #returns all the required information about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars =  parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url\n",
    "\n",
    "def get_topic_repos(topic_doc) :\n",
    "  \n",
    "   # get the h3 tags containing repo title,repo url and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3',{'class':h3_selection_class })\n",
    "    \n",
    "   #  get star tags \n",
    "    star_tags = topic_doc.find_all('span',{'class': 'Counter js-social-count'})\n",
    "    \n",
    "   # create dict\n",
    "    topic_repos_dict = {\n",
    "                'UserName': [],\n",
    "                'Repo_Name': [],\n",
    "                'Stars': [],\n",
    "                'Repo_URL': []}\n",
    "    \n",
    "   # get repo_info\n",
    "    for i in range(len(repo_tags)) :\n",
    "                repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "                topic_repos_dict['UserName'].append(repo_info[0])\n",
    "                topic_repos_dict['Repo_Name'].append(repo_info[1])\n",
    "                topic_repos_dict['Stars'].append(repo_info[2])\n",
    "                topic_repos_dict['Repo_URL'].append(repo_info[3])\n",
    "                \n",
    "    return pd.DataFrame(topic_repos_dict) \n",
    "\n",
    "def scrape_topic(topic_url, topic_name):\n",
    "    \n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(topic_name + 'csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66764db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = topic_urls[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649866e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic4_doc = get_topic_page(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3620b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic4_repos = get_topic_repos(topic4_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic4_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22362c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_urls[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7a418",
   "metadata": {},
   "outputs": [],
   "source": [
    " get_topic_repos(get_topic_page(topic_urls[6])).to_csv('ansible.csv',index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909a613",
   "metadata": {},
   "source": [
    "#### Write a single function to :\n",
    "###### 1. Get the list of topics from the topics page\n",
    "###### 2. Get the list of top repos from the individual topic pages\n",
    "###### 3. For each topic , create a csv of the top repos for the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc11dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles\n",
    "\n",
    "def get_topic_descriptions(doc):\n",
    "    selection_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_descriptions = []\n",
    "    for tag in topic_desc_tags:\n",
    "         topic_descriptions.append(tag.text.strip())\n",
    "    return topic_descriptions  \n",
    "\n",
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-grow-0'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    \n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls\n",
    "    \n",
    "    \n",
    "def scrape_topics():\n",
    "    topic_urls = 'https://github.com/topics'\n",
    "    response = requests.get(topic_urls)   \n",
    "    if response.status_code != 200:\n",
    "        raise Exception ('Failed to load page{}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    topics_dict = {\n",
    "        'Title' : get_topic_titles(doc),\n",
    "        'Description' : get_topic_descriptions(doc),\n",
    "        'URL' : get_topic_urls(doc)\n",
    "    }   \n",
    "    return pd.DataFrame(topics_dict)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topic_df = scrape_topics()\n",
    "    for index, row in topic_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['Title']))\n",
    "        scrape_topic(row['URL'],row['Title'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4882a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_topics_repos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
