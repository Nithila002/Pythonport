{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2fd000",
   "metadata": {},
   "source": [
    "## SCRAPPING_GITHUB_TOP_RESPIRATORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761db881",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "\n",
    "- Scrapping data from https://github.com/topics\n",
    "- Getting a list of topics and for each topic getting a topic title,topic page  url and topic description.\n",
    "- For each topic getting top 25 repositories from topic page\n",
    "- For each repository grabbing the repo name, username, stars and repo URL\n",
    "- For each topic created a csv file \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98dd278",
   "metadata": {},
   "source": [
    "## Scrape list of topics\n",
    "\n",
    "- Using requests to download the page\n",
    "- Use of BS4 to parse and extract information\n",
    "- Converting to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28e2b5",
   "metadata": {},
   "source": [
    "#### Downloading the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_topics_page():\n",
    "    topic_urls = 'https://github.com/topics'\n",
    "    response = requests.get(topic_urls)   \n",
    "    if response.status_code != 200:\n",
    "        raise Exception ('Failed to load page{}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3376bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topics_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266585e",
   "metadata": {},
   "source": [
    "#### Helper functions to parse information from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900d07e",
   "metadata": {},
   "source": [
    "`get_tool_titles` is used to get the list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a33596",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c7e73",
   "metadata": {},
   "source": [
    "##### Similarly defined functions for decriptiond and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descriptions(doc):\n",
    "    selection_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_descriptions = []\n",
    "    for tag in topic_desc_tags:\n",
    "         topic_descriptions.append(tag.text.strip())\n",
    "    return topic_descriptions  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-grow-0'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    \n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6dde2",
   "metadata": {},
   "source": [
    "#### Putting all together in a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topic_urls = 'https://github.com/topics'\n",
    "    response = requests.get(topic_urls)   \n",
    "    if response.status_code != 200:\n",
    "        raise Exception ('Failed to load page{}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    topics_dict = {\n",
    "        'Title' : get_topic_titles(doc),\n",
    "        'Description' : get_topic_descriptions(doc),\n",
    "        'URL' : get_topic_urls(doc)\n",
    "    }   \n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa50b95",
   "metadata": {},
   "source": [
    "## Getting the top 25 repositories from topic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52297e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    \n",
    "    # download the page\n",
    "    response = requests.get(topic_url)\n",
    "    \n",
    "   # check successfull response\n",
    "    if response.status_code != 200:\n",
    "          raise Exception ('Failed to load page{}'.format(topic_url))\n",
    "            \n",
    "   # parse using beautifulsoup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')   \n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page('https://github.com/topics/3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f43d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h3_tag, star_tag):\n",
    "    \n",
    "    #returns all the required information about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars =  parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc) :\n",
    "  \n",
    "   # get the h3 tags containing repo title,repo url and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3',{'class':h3_selection_class })\n",
    "    \n",
    "   #  get star tags \n",
    "    star_tags = topic_doc.find_all('span',{'class': 'Counter js-social-count'})\n",
    "    \n",
    "   # create dict\n",
    "    topic_repos_dict = {\n",
    "                'UserName': [],\n",
    "                'Repo_Name': [],\n",
    "                'Stars': [],\n",
    "                'Repo_URL': []}\n",
    "    \n",
    "   # get repo_info\n",
    "    for i in range(len(repo_tags)) :\n",
    "                repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "                topic_repos_dict['UserName'].append(repo_info[0])\n",
    "                topic_repos_dict['Repo_Name'].append(repo_info[1])\n",
    "                topic_repos_dict['Stars'].append(repo_info[2])\n",
    "                topic_repos_dict['Repo_URL'].append(repo_info[3])\n",
    "                \n",
    "    return pd.DataFrame(topic_repos_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a114a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url, topic_name):\n",
    "    \n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(topic_name + 'csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707622e3",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "- Function to get the list of topics\n",
    "- Function to create a csv file for scrapped reports from a topic page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topic_df = scrape_topics()\n",
    "    for index, row in topic_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['Title']))\n",
    "        scrape_topic(row['URL'],row['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3bce9",
   "metadata": {},
   "source": [
    "Can read and display a CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
